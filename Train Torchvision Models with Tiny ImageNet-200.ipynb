{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train AlexNet with Tiny ImageNet-200\n",
    "\n",
    "We are going to train the [AlexNet](https://arxiv.org/abs/1404.5997) model to work with the [Tiny ImageNet-200](https://tiny-imagenet.herokuapp.com/), a subset of ImageNet with 200 classes.\n",
    "\n",
    "But we are not going to train it from the scratch, we are going to use the pre-trained model from [torchvision](http://pytorch.org/docs/master/torchvision/models.html), stripping the last layer and replacing it by a fresh layer that outputs 200 units instead of the original 1000 units for ImageNet. The last layer is the one we are going to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import json\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some constants for the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"../data/tiny-imagenet-200/\"\n",
    "num_classes = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and pre-processing\n",
    "\n",
    "First we load and pre-process the data according to the pre-trained model [documentation](http://pytorch.org/docs/master/torchvision/models.html), applying transformations using [this example](https://github.com/pytorch/examples/blob/42e5b996718797e45c46a25c55b031e6768f8440/imagenet/main.py#L89-L113).\n",
    "\n",
    "For training data, we resize and crop randomly to get images of 224x224, flip horizontally some of the images, transform them to a tensor and finally normalize them to have values between 0 and 1. The magic normalization parameters come from the example.\n",
    "\n",
    "For the validation data we use less corrupted images, only resizing them and cropping them in the center and then appliying the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# modify this depending on memory constraints\n",
    "batch_size = 64\n",
    "\n",
    "# the magic normalization parameters come from the example\n",
    "transform_mean = np.array([ 0.485, 0.456, 0.406 ])\n",
    "transform_std = np.array([ 0.229, 0.224, 0.225 ])\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean = transform_mean, std = transform_std),\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean = transform_mean, std = transform_std),\n",
    "])\n",
    "\n",
    "traindir = os.path.join(directory, \"train\")\n",
    "# be careful with this set, the labels are not defined using the directory structure\n",
    "valdir = os.path.join(directory, \"val\")\n",
    "\n",
    "train = datasets.ImageFolder(traindir, train_transform)\n",
    "val = datasets.ImageFolder(valdir, val_transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "assert num_classes == len(train_loader.dataset.classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label madness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[WordNet](https://wordnet.princeton.edu/) is a large lexical database of English. ImageNet uses a subset of this database as labels for the images, and the Tiny ImageNet-200 uses an even smaller subset. The Tiny ImageNet-200 comes with a map between WordNet ids and WordNet definitions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_labels = {}\n",
    "with open(os.path.join(directory, \"words.txt\"), \"r\") as dictionary_file:\n",
    "    line = dictionary_file.readline()\n",
    "    while line:\n",
    "        label_id, label = line.strip().split(\"\\t\")\n",
    "        small_labels[label_id] = label\n",
    "        line = dictionary_file.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_labels.items()[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The train subdirectory of Tiny ImageNet-200 has a collection of subdirectories, named using to the WordNet ids to label the images that they contain. The torchvision data loader uses the names of the subdirectories as labels, but replaces them with numeric indices when iterating the batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(traindir)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {}\n",
    "label_ids = {}\n",
    "for label_index, label_id in enumerate(train_loader.dataset.classes):\n",
    "    label = small_labels[label_id]\n",
    "    labels[label_index] = label\n",
    "    label_ids[label_id] = label_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.items()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_ids.items()[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another problem is that the validation directory only has one subdirectory called `images`. The labels for every image inside this subdirectory are defined in a file called `val_annotations.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_label_map = {}\n",
    "with open(os.path.join(directory, \"val/val_annotations.txt\"), \"r\") as val_label_file:\n",
    "    line = val_label_file.readline()\n",
    "    while line:\n",
    "        file_name, label_id, _, _, _, _ = line.strip().split(\"\\t\")\n",
    "        val_label_map[file_name] = label_id\n",
    "        line = val_label_file.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_label_map.items()[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we update the Tiny ImageNet-200 validation set labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader.dataset.imgs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(val_loader.dataset.imgs)):\n",
    "    file_path = val_loader.dataset.imgs[i][0]\n",
    "    \n",
    "    file_name = os.path.basename(file_path)\n",
    "    label_id = val_label_map[file_name]\n",
    "    \n",
    "    val_loader.dataset.imgs[i] = (file_path, label_ids[label_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader.dataset.imgs[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Xavier weight initialization for the extra layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(m):\n",
    "    weight_shape = list(m.weight.data.size())\n",
    "    fan_in = weight_shape[1]\n",
    "    fan_out = weight_shape[0]\n",
    "    w_bound = np.sqrt(6. / (fan_in + fan_out))\n",
    "    m.weight.data.uniform_(-w_bound, w_bound)\n",
    "    m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the pre-trained error, get the weights and remove the last lawer parameters.\n",
    "\n",
    "Create an empty model with the desired last layer size, copy the parameters and initialize the rest.\n",
    "\n",
    "Note that only the new parameters will be used for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_trained_model = models.alexnet(pretrained=True)\n",
    "state_dict = pre_trained_model.state_dict()\n",
    "state_dict.pop(\"classifier.6.weight\")\n",
    "state_dict.pop(\"classifier.6.bias\")\n",
    "model = models.alexnet(num_classes=num_classes)\n",
    "model.load_state_dict(state_dict, strict=False)\n",
    "\n",
    "parameters = model.classifier[6].parameters()\n",
    "initialize_weights(model.classifier[6])\n",
    "\n",
    "model = model.cuda()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(parameters, lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the percentage of error in the top-k most probable classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_k_error(top_k, total):\n",
    "    return 100.0 - top_k / total * 100.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run one epoch, either with training or evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch(loader, train=True, log_every=100):\n",
    "    running_loss = 0.0\n",
    "    running_top_1 = 0.0\n",
    "    running_top_5 = 0.0\n",
    "    running_total = 0.0\n",
    "    \n",
    "    epoch_top_1 = 0.0\n",
    "    epoch_top_5 = 0.0\n",
    "    epoch_total = 0.0\n",
    "    \n",
    "    for batch_number, (batch_inputs, batch_labels) in enumerate(loader):\n",
    "        batch_inputs, batch_labels = Variable(batch_inputs.cuda()), Variable(batch_labels.cuda())\n",
    "\n",
    "        if train:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        batch_logits = model(batch_inputs)\n",
    "        \n",
    "        if train:\n",
    "            batch_loss = criterion(batch_logits, batch_labels)\n",
    "            batch_loss.backward()\n",
    "        \n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += batch_loss.data.cpu()[0]\n",
    "        \n",
    "        batch_labels = batch_labels.data.cpu().numpy()\n",
    "        batch_predictions = batch_logits.topk(5)[1].data.cpu().numpy()\n",
    "    \n",
    "        for i in range(len(batch_labels)):\n",
    "            if batch_labels[i] == batch_predictions[i, 0]:\n",
    "                running_top_1 += 1\n",
    "                running_top_5 += 1\n",
    "                epoch_top_1 += 1\n",
    "                epoch_top_5 += 1\n",
    "            else:\n",
    "                for j in range(1, 5):\n",
    "                    if batch_labels[i] == batch_predictions[i, j]:\n",
    "                        running_top_5 += 1\n",
    "                        epoch_top_5 += 1\n",
    "                        break\n",
    "        \n",
    "        running_total += len(batch_labels)\n",
    "        epoch_total += len(batch_labels)\n",
    "\n",
    "        if batch_number % log_every == log_every - 1:\n",
    "            if train:\n",
    "                print(\"[Batch {:5d}] Loss: {:.3f} Top-1 Error: {:.3f} Top-5 Error: {:.3f}\".format(\n",
    "                    batch_number + 1,\n",
    "                    running_loss / log_every,\n",
    "                    top_k_error(running_top_1, running_total),\n",
    "                    top_k_error(running_top_5, running_total)\n",
    "                ))\n",
    "            \n",
    "            running_loss = 0.0\n",
    "            running_top_1 = 0.0\n",
    "            running_top_5 = 0.0\n",
    "            running_total = 0.0\n",
    "            \n",
    "    return top_k_error(epoch_top_1, epoch_total), top_k_error(epoch_top_5, epoch_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1 # modify this to run different number of epochs\n",
    "\n",
    "for epoch_number in range(num_epochs):\n",
    "\n",
    "    train_top_1_error, train_top_5_error = run_epoch(train_loader, train=True)\n",
    "    print(\"[Epoch {:3d}] Training Top-1 Error: {:.3f} Top-5 Error: {:.3f}\".format(\n",
    "        epoch_number + 1, train_top_1_error, train_top_5_error))\n",
    "    \n",
    "    val_top_1_error, val_top_5_error = run_epoch(val_loader, train=False)\n",
    "    print(\"[Epoch {:3d}] Validation Top-1 Error: {:.3f} Top-5 Error: {:.3f}\".format(\n",
    "        epoch_number + 1, val_top_1_error, val_top_5_error))\n",
    "\n",
    "print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot some samples\n",
    "\n",
    "To be sure that we did not mess up with the labels and see how the model works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_images = 10 # modify the number of images shown\n",
    "\n",
    "batch_inputs, batch_labels = next(iter(val_loader))\n",
    "batch_inputs = Variable(batch_inputs.cuda(), volatile=True)\n",
    "\n",
    "batch_logits = model(batch_inputs)\n",
    "\n",
    "batch_labels = batch_labels.numpy()\n",
    "batch_predictions = batch_logits.topk(5)[1].data.cpu().numpy()\n",
    "\n",
    "cell_number = 1\n",
    "\n",
    "plt.figure(figsize=(4, num_images * 2))\n",
    "\n",
    "for image_number in range(num_images):\n",
    "    image = np.copy(batch_inputs.data[image_number].cpu().numpy())\n",
    "    image = np.transpose(image, (1, 2, 0))\n",
    "    for channel in range(3):\n",
    "        image[:, :, channel] = image[:, :, channel] * transform_std[channel] + transform_mean[channel]\n",
    "\n",
    "    label = labels[batch_labels[image_number]]\n",
    "\n",
    "    plt.subplot(num_images, 2, cell_number)\n",
    "\n",
    "    ax = plt.imshow(image)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "    cell_number += 1\n",
    "\n",
    "    plt.subplot(num_images, 2, cell_number)\n",
    "    plt.axis(\"off\")\n",
    "    plt.xlim(0, 1)\n",
    "    plt.ylim(0, 1)\n",
    "    plt.text(0, 0.85, \"Label: {}\".format(label))\n",
    "    for prediction_number in range(5):\n",
    "        plt.text(0, 0.85 - 0.15 * (prediction_number + 1), \"Prediction-{:d}: {}\".format(\n",
    "            prediction_number + 1, labels[batch_predictions[image_number, prediction_number]]))\n",
    "    \n",
    "    cell_number += 1\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
